{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The problem setup\n",
    "- A friend tells you they have some data, and ask if you \"can do machine learning on it\"\n",
    "- After discussion, you realize they have a classification task (Predicting label given features)\n",
    "- You say to yourself \"aha, I can use a supervised learning classifier to predict the labels from the features\", and tell your friend \"yes I can use machine learning for this\"\n",
    "- How do you proceed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About the code\n",
    "- Headings with \\*stars\\* mean you may want to edit this for your specific problem/data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "from sklearn.decomposition import PCA, SparsePCA, FactorAnalysis\n",
    "from sklearn.metrics import get_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should import from elsewhere\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import RidgeClassifier, LogisticRegression \n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import time\n",
    "def get_time(): # used to create time stamp for figures\n",
    "    t = time.localtime()\n",
    "    return \"{}_{}_{}_{}_{}\".format(t.tm_mon, t.tm_mday, t.tm_hour, t.tm_min, t.tm_sec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \\*Set important constants\\*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_LOC = \"../results\"  # path to store results, if none current directory is used\n",
    "SCORING = \"balanced_accuracy\"\n",
    "TEST_SIZE = 0.3     # proportion of data to withhold for testing\n",
    "CV = 5              # number of folds for GridSearchCV\n",
    "REPS_PER_CLF = 1    # number of trials of GridSearchCV with each CLF\n",
    "DIM_RED = None      # options- None, \"PCA\", \"SPCA\", \"FA\"\n",
    "N_COMPS =  None     # None or int < n_feats   (5, 22 are interesting)\n",
    "\n",
    "# DATA_LOC = \"data_pain.csv\"\n",
    "# TARGET_COL = \"Group\"\n",
    "# REMOVE_COLS = [\"Group\", \"Study ID\"]\n",
    "scorer = get_scorer(SCORING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \\*Set up data\\* \n",
    "### The load_data method is setup to load some common test datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_data(loc=DATA_LOC):\n",
    "#     df = read_csv(loc)\n",
    "#     y = df[TARGET_COL]\n",
    "#     print(\"Removing columns \", REMOVE_COLS)\n",
    "#     df = df.drop(REMOVE_COLS, axis=1)\n",
    "#     return df, y\n",
    "\n",
    "\n",
    "def load_data(n=0):\n",
    "    if n==0:\n",
    "        from sklearn.datasets import load_digits\n",
    "        digits = load_digits()\n",
    "        return digits.data, digits.target\n",
    "    if n==1:\n",
    "        from sklearn.datasets import load_breast_cancer\n",
    "        return load_breast_cancer(return_X_y=True)\n",
    "    if n==2:\n",
    "        from sklearn.datasets import fetch_openml\n",
    "        X,y =  fetch_openml(\"credit-g\", return_X_y=True)\n",
    "        return X, y==\"good\"\n",
    "    else:\n",
    "        print(\"Invalid dataset! {}\".format(n))\n",
    "\n",
    "      \n",
    "X, y = load_data(2) # get data \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, stratify=y) \n",
    "\n",
    "# scale\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DIM_RED is not None:\n",
    "    dr = None\n",
    "    if DIM_RED == \"PCA\":\n",
    "        dr = PCA(N_COMPS)\n",
    "    elif DIM_RED == \"SPCA\":\n",
    "        dr = SPCA(N_COMPS)\n",
    "    elif DIM_RED == \"FA\":\n",
    "        dr = FactorAnalysis(N_COMPS)\n",
    "    else:\n",
    "        raise(\"Invalid DIM_RED {}\".format(DIM_RED))\n",
    "        \n",
    "    dr.fit(X_train)\n",
    "    X_train = dr.transform(X_train)\n",
    "    X_test = dr.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \\*Set up classifiers and params \\*\n",
    "### (see get_clfs_and_params for help)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(sklearn.ensemble.forest.RandomForestClassifier,\n",
       " {'bootstrap': [True],\n",
       "  'class_weight': [None],\n",
       "  'criterion': ['entropy'],\n",
       "  'max_depth': [None],\n",
       "  'max_features': ['auto'],\n",
       "  'max_leaf_nodes': [None],\n",
       "  'min_impurity_decrease': [0.0],\n",
       "  'min_impurity_split': [None],\n",
       "  'min_samples_leaf': [1, 2, 4, 8],\n",
       "  'min_samples_split': [2, 4, 8],\n",
       "  'min_weight_fraction_leaf': [0.0],\n",
       "  'n_estimators': [50, 100, 250],\n",
       "  'n_jobs': [None],\n",
       "  'oob_score': [False],\n",
       "  'random_state': [None],\n",
       "  'verbose': [0],\n",
       "  'warm_start': [False]})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfs = [\n",
    "    (RandomForestClassifier ,\n",
    " {\n",
    "\t'bootstrap': [True],\n",
    "\t'class_weight': [None],\n",
    "\t'criterion': ['entropy'],\n",
    "\t'max_depth': [None],\n",
    "\t'max_features': ['auto'],\n",
    "\t'max_leaf_nodes': [None],\n",
    "\t'min_impurity_decrease': [0.0],\n",
    "\t'min_impurity_split': [None],\n",
    "\t'min_samples_leaf': [1, 2, 4, 8],\n",
    "\t'min_samples_split': [2, 4, 8],\n",
    "\t'min_weight_fraction_leaf': [0.0],\n",
    "\t'n_estimators': [50, 100, 250],\n",
    "\t'n_jobs': [None],\n",
    "\t'oob_score': [False],\n",
    "\t'random_state': [None],\n",
    "\t'verbose': [0],\n",
    "\t'warm_start': [False],\n",
    "\n",
    "\n",
    "}),\n",
    "(AdaBoostClassifier ,\n",
    " {\n",
    "\t'algorithm': ['SAMME.R'],\n",
    "\t'base_estimator': [None],\n",
    "\t'learning_rate': [0.5, 1.0, 1.5, 2.5],\n",
    "\t'n_estimators': [50, 100, 250],\n",
    "\t'random_state': [None],\n",
    "\n",
    "\n",
    "}),\n",
    "(GradientBoostingClassifier ,\n",
    " {\n",
    "\t'criterion': ['friedman_mse'],\n",
    "\t'init': [None],\n",
    "\t'learning_rate': [0.05, 0.1, 0.15, 0.25],\n",
    "\t'loss': ['deviance'],\n",
    "\t'max_depth': [3],\n",
    "\t'max_features': [None],\n",
    "\t'max_leaf_nodes': [None],\n",
    "\t'min_impurity_decrease': [0.0],\n",
    "\t'min_impurity_split': [None],\n",
    "\t'min_samples_leaf': [1, 2, 4, 8],\n",
    "\t'min_samples_split': [2, 4, 8],\n",
    "\t'min_weight_fraction_leaf': [0.0],\n",
    "\t'n_estimators': [50, 100, 250],\n",
    "\t'n_iter_no_change': [None],\n",
    "\t'presort': ['auto'],\n",
    "\t'random_state': [None],\n",
    "\t'subsample': [1.0],\n",
    "\t'tol': [0.0001],\n",
    "\t'validation_fraction': [0.1],\n",
    "\t'verbose': [0],\n",
    "\t'warm_start': [False],\n",
    "\n",
    "\n",
    "}),\n",
    "(RidgeClassifier ,\n",
    " {\n",
    "\t'alpha': [0.5, 1.0, 1.5, 2.5],\n",
    "\t'class_weight': [None],\n",
    "\t'copy_X': [True],\n",
    "\t'fit_intercept': [True],\n",
    "\t'max_iter': [None],\n",
    "\t'normalize': [False],\n",
    "\t'random_state': [None],\n",
    "\t'solver': ['auto'],\n",
    "\t'tol': [0.001],\n",
    "\n",
    "\n",
    "}),\n",
    "(LogisticRegression ,\n",
    " {\n",
    "\t'C': [0.5, 1.0, 1.5, 2.5],\n",
    "\t'class_weight': [None],\n",
    "\t'dual': [False],\n",
    "\t'fit_intercept': [True],\n",
    "\t'intercept_scaling': [1],\n",
    "\t'l1_ratio': [None],\n",
    "\t'max_iter': [100],\n",
    "\t'multi_class': ['warn'],\n",
    "\t'n_jobs': [None],\n",
    "\t'penalty': ['l2'],\n",
    "\t'random_state': [None],\n",
    "\t'solver': ['warn'],\n",
    "\t'tol': [0.0001],\n",
    "\t'verbose': [0],\n",
    "\t'warm_start': [False],\n",
    "\n",
    "\n",
    "}),\n",
    "(LinearDiscriminantAnalysis ,\n",
    " {\n",
    "\t'n_components': [None],\n",
    "\t'priors': [None],\n",
    "\t'shrinkage': [None],\n",
    "\t'solver': ['svd'],\n",
    "\t'store_covariance': [True],\n",
    "\t'tol': [0.0001],\n",
    "\n",
    "\n",
    "}),\n",
    "(QuadraticDiscriminantAnalysis ,\n",
    " {\n",
    "\t'priors': [None],\n",
    "\t'reg_param': [0.0],\n",
    "\t'store_covariance': [True],\n",
    "\t'tol': [0.0001],\n",
    "\n",
    "\n",
    "}),\n",
    "(KNeighborsClassifier ,\n",
    " {\n",
    "\t'algorithm': ['auto'],\n",
    "\t'leaf_size': [30],\n",
    "\t'metric': ['minkowski'],\n",
    "\t'metric_params': [None],\n",
    "\t'n_jobs': [None],\n",
    "\t'n_neighbors': [3, 5, 7, 9],\n",
    "\t'p': [1.5, 2, 3, 4, 5, 6],\n",
    "\t'weights': ['uniform'],\n",
    "\n",
    "\n",
    "}),\n",
    "(SVC ,\n",
    " {\n",
    "\t'C': [1.0],\n",
    "\t'cache_size': [200],\n",
    "\t'class_weight': [None],\n",
    "\t'coef0': [0.0],\n",
    "\t'decision_function_shape': ['ovr'],\n",
    "\t'degree': [3],\n",
    "\t'gamma': ['auto', \"scale\"],\n",
    "\t'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "\t'max_iter': [-1],\n",
    "\t'probability': [False],\n",
    "\t'random_state': [None],\n",
    "\t'shrinking': [True],\n",
    "\t'tol': [0.001],\n",
    "\t'verbose': [False],\n",
    "\n",
    "}),\n",
    "]\n",
    "clfs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do learning (ie fit the classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<class 'sklearn.ensemble.forest.RandomForestClassifier'>, {'bootstrap': [True], 'class_weight': [None], 'criterion': ['entropy'], 'max_depth': [None], 'max_features': ['auto'], 'max_leaf_nodes': [None], 'min_impurity_decrease': [0.0], 'min_impurity_split': [None], 'min_samples_leaf': [1, 2, 4, 8], 'min_samples_split': [2, 4, 8], 'min_weight_fraction_leaf': [0.0], 'n_estimators': [50, 100, 250], 'n_jobs': [None], 'oob_score': [False], 'random_state': [None], 'verbose': [0], 'warm_start': [False]})\n",
      "(<class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, {'algorithm': ['SAMME.R'], 'base_estimator': [None], 'learning_rate': [0.5, 1.0, 1.5, 2.5], 'n_estimators': [50, 100, 250], 'random_state': [None]})\n",
      "(<class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, {'criterion': ['friedman_mse'], 'init': [None], 'learning_rate': [0.05, 0.1, 0.15, 0.25], 'loss': ['deviance'], 'max_depth': [3], 'max_features': [None], 'max_leaf_nodes': [None], 'min_impurity_decrease': [0.0], 'min_impurity_split': [None], 'min_samples_leaf': [1, 2, 4, 8], 'min_samples_split': [2, 4, 8], 'min_weight_fraction_leaf': [0.0], 'n_estimators': [50, 100, 250], 'n_iter_no_change': [None], 'presort': ['auto'], 'random_state': [None], 'subsample': [1.0], 'tol': [0.0001], 'validation_fraction': [0.1], 'verbose': [0], 'warm_start': [False]})\n",
      "(<class 'sklearn.linear_model.ridge.RidgeClassifier'>, {'alpha': [0.5, 1.0, 1.5, 2.5], 'class_weight': [None], 'copy_X': [True], 'fit_intercept': [True], 'max_iter': [None], 'normalize': [False], 'random_state': [None], 'solver': ['auto'], 'tol': [0.001]})\n",
      "(<class 'sklearn.linear_model.logistic.LogisticRegression'>, {'C': [0.5, 1.0, 1.5, 2.5], 'class_weight': [None], 'dual': [False], 'fit_intercept': [True], 'intercept_scaling': [1], 'l1_ratio': [None], 'max_iter': [100], 'multi_class': ['warn'], 'n_jobs': [None], 'penalty': ['l2'], 'random_state': [None], 'solver': ['warn'], 'tol': [0.0001], 'verbose': [0], 'warm_start': [False]})\n",
      "(<class 'sklearn.discriminant_analysis.LinearDiscriminantAnalysis'>, {'n_components': [None], 'priors': [None], 'shrinkage': [None], 'solver': ['svd'], 'store_covariance': [True], 'tol': [0.0001]})\n",
      "(<class 'sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis'>, {'priors': [None], 'reg_param': [0.0], 'store_covariance': [True], 'tol': [0.0001]})\n",
      "(<class 'sklearn.neighbors.classification.KNeighborsClassifier'>, {'algorithm': ['auto'], 'leaf_size': [30], 'metric': ['minkowski'], 'metric_params': [None], 'n_jobs': [None], 'n_neighbors': [3, 5, 7, 9], 'p': [1.5, 2, 3, 4, 5, 6], 'weights': ['uniform']})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<class 'sklearn.svm.classes.SVC'>, {'C': [1.0], 'cache_size': [200], 'class_weight': [None], 'coef0': [0.0], 'decision_function_shape': ['ovr'], 'degree': [3], 'gamma': ['auto', 'scale'], 'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'max_iter': [-1], 'probability': [False], 'random_state': [None], 'shrinking': [True], 'tol': [0.001], 'verbose': [False]})\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "TIME = get_time()\n",
    "\n",
    "def fit_clf(clf):\n",
    "    print(clf)\n",
    "    if REPS_PER_CLF > 1:\n",
    "        return [GridSearchCV(clf[0](), clf[1], cv=CV, scoring=SCORING).fit(X_train, y_train) for _ in range(REPS)] # fit multiple times \n",
    "    else:\n",
    "        return GridSearchCV(clf[0](), clf[1], cv=CV, scoring=SCORING).fit(X_train, y_train)\n",
    "    \n",
    "clfs = list(map(\n",
    "    fit_clf , clfs \n",
    "))\n",
    "\n",
    "if type(clfs[0]) is list:\n",
    "    clfs = [item for sublist in clfs for item in sublist] # flatten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# benchmark \n",
    "class RandomClf():\n",
    "    def __init__(self, true_vals ):        \n",
    "        self.vals = np.unique(true_vals)\n",
    "        self.props = [sum(true_vals==val)/len(true_vals) for val in self.vals]\n",
    "        \n",
    "        \n",
    "    def predict(self, X):\n",
    "        return np.random.choice(self.vals, p=self.props, size=len(X), replace=True)\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "rclf = RandomClf(y_test)\n",
    "\n",
    "\n",
    "random_scores = np.array([scorer(y_true=y_test, estimator=rclf, X=X_test) for _ in range(len(clfs))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not RESULTS_LOC: RESULTS_LOC = \".\"\n",
    "cv_fit_results = list(map(\n",
    "    lambda clf: clf.cv_results_[\"mean_test_score\"], clfs\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clf_name_from_gs(gs):\n",
    "    return str(gs.estimator).split(\"(\")[0]\n",
    "    \n",
    "names = list(map(\n",
    "    clf_name_from_gs, clfs\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_results = list(map(\n",
    "    lambda clf: scorer(y_true=y_test, estimator=clf, X=X_test), clfs\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_fit_results.append(random_scores)\n",
    "names.append(\"Random\")\n",
    "score_results.append(max(random_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "n_results = len(cv_fit_results)\n",
    "plt.boxplot(cv_fit_results)\n",
    "plt.xticks(range(1, n_results+1), names, rotation=90)\n",
    "plt.title(\"CV results from param search (1pt per param setting)\")\n",
    "plt.ylabel(\"{} score\".format(SCORING))\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"{}/cv_results_{}_{}-{}_{}.png\".format(RESULTS_LOC ,SCORING, DIM_RED, N_COMPS, TIME))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(range(len(score_results)),score_results)\n",
    "# plt.scatter(names,score_results)\n",
    "plt.xticks(rotation=90)\n",
    "plt.xticks(range(n_results), names, rotation=90)\n",
    "n_results = len(score_results)\n",
    "# plt.plot(range(n_results), [0.5]*n_results)\n",
    "plt.title(\"Test scores for all algos (1pt per algo)\")\n",
    "plt.ylabel(\"{} score\".format(SCORING))\n",
    "# plt.ylabel(SCORING)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"{}/scores_max{:.3f}_{}_{}-{}_{}.png\".format(RESULTS_LOC, max(score_results), SCORING, DIM_RED, N_COMPS, TIME)) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(score_results)\n",
    "plt.title(\"Distribution of scores for all algos (1pt per algo)\")\n",
    "plt.ylabel(\"{} score\".format(SCORING))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"{}/best_clfs_{}.txt\".format(RESULTS_LOC ,TIME), \"w\") as f:\n",
    "    for clf in clfs:\n",
    "        f.write(str(clf.best_estimator_) + \"\\n\\n\")\n",
    "#         f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
